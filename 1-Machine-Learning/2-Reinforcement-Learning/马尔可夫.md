# 马尔可夫



## 马尔可夫链

未来只取决于现在，跟过去无关

Markov Decision Process (MDP)



State $s_t$ is Markovian if and only if:
$$
p
$$




## 马尔可夫奖励过程







策略迭代和价值迭代：

value based是v参与迭代，policy根据迭代的v决定，不论v迭代几步以后来决定policy，可能每迭代一步就update一下policy，也可能迭代一系列之后update。policy based是policy直接参与迭代