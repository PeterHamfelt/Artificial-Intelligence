[toc]

## 基础

概率P是对一个事件而言的，A是一个时间，P(A)就是这个事件发生的概率



$X$ 是一个随机变量（Random Variable），$x$ 是它的一个实现（Realization）

$P(x;\beta)$ ：$\beta$ 是 $x$ 的参数，然后表示 $x$ 出现的概率

$P(x \mid y)$ ：条件概率

$P(x,y)$ : 联合概率



例如高斯函数，就可以用 $p(x;\mu,\sigma)$ 来表示，因为 $\mu, \sigma$ 都是参数。



## 概率函数

概率质量函数：Probability mass function (PMF)，分布律

概率密度函数：Probability density function (PDF)

累积分布函数：Cumulative distribution function (CDF)



**PMF**是针对离散随机变量而言的，是随机变量在各特定取值上的概率

> 例如抛骰子，每一面朝上的概率都是1/6，那么表示出的PMF就是：
>
> $f_{X}(x)=\left\{\begin{array}{l}{\frac{1}{6} \text { if } x \in\{1,2,3,4,5,6\}} \\ {0 \text { if } x \notin\{1,2,3,4,5,6\}}\end{array}\right.$



**PDF**是针对连续随机变量而言的，因为连续所以我们无法描述变量落在某一点上的概率，只能说落在某一区间上的概率，官方描述为：在某个确定的取值点附近的可能性的函数

我们经常看到的均匀分布，高斯分布，说的就是概率密度函数。

> 例如均匀分布，它的概率密度函数是：
>
> $f_X(x)=\left\{\begin{array}{ll}{\frac{1}{b-a}} & {\text { for } a \leq x \leq b} \\ {0} & {\text { elsewhere }}\end{array}\right.$
>
> ![1567845043390](https://img-blog.csdnimg.cn/20190920095635829.png)
>
> 如果我们说落在每一点上的概率是$\frac{1}{b-a}$，那么岂不是（b-a）个点就使得总概率为1了吗？所以并不是这样，应该是PDF函数的积分才是1，也即PDF函数图像的面积。



**CDF**是是概率密度函数的积分

$F(x)=P(X<=x)$



## 定理

### 大数定律

在随机事件的大量重复出现中，往往呈现几乎必然的规律，也即在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。



### 中心极限定理

> Central limit theorem (CLT)

大量相互独立随机变量的均值经适当标准化后依分布收敛于正态分布



- 棣莫佛－拉普拉斯定理 (de Moivre - Laplace)

  参数为$n, p$的二项分布以$np$为均值、$np(1-p)$为方差的正态分布为极限

  

- 林德伯格－列维定理 (Lindeberg-Levy)

  独立同分布、且数学期望和方差有限的随机变量序列的标准化和以标准正态分布为极限

  

- 林德伯格-费勒定理

  满足一定条件时，独立，但不同分布的随机变量序列的标准化和依然以标准正态分布为极限

  

  林德伯格条件 (Lindeberg condition)：

  

## 全期望公式

$$
\begin{aligned}
\mathbb{E}[\mathbb{E}[X|Y]]
&= \sum_y \mathbb{E}[X|Y=y] P(Y=y)\\
&= \sum_y \sum_x x P(X=x|Y=y) P(Y=y) \\
&= \sum_x x \sum_y P(X=x|Y=y) P(Y=y) \\
&= \sum_x x P(X=x)  \\
&= \mathbb{E}[X]
\end{aligned}
$$

